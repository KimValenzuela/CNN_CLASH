{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KimValenzuela/CNN_CLASH/blob/master/second_CNN_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wW78Q03fjHzo"
      },
      "outputs": [],
      "source": [
        "!pip install poetry"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9dKVIx9kjFaS",
        "outputId": "75167cb2-3943-4f29-8a8e-bebac0f6c956"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'CNN_CLASH'...\n",
            "remote: Enumerating objects: 7454, done.\u001b[K\n",
            "remote: Counting objects: 100% (62/62), done.\u001b[K\n",
            "remote: Compressing objects: 100% (43/43), done.\u001b[K\n",
            "remote: Total 7454 (delta 31), reused 46 (delta 19), pack-reused 7392\u001b[K\n",
            "Receiving objects: 100% (7454/7454), 80.23 MiB | 17.26 MiB/s, done.\n",
            "Resolving deltas: 100% (51/51), done.\n"
          ]
        }
      ],
      "source": [
        "!rm -rf /content/CNN_CLASH/ && git clone -b master https://github.com/KimValenzuela/CNN_CLASH.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_i2s2lg7jIxW",
        "outputId": "4cbd81cd-3d75-41c9-ebb1-83611bec22fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34mInstalling dependencies from lock file\u001b[39m\n",
            "\n",
            "\u001b[39;1mPackage operations\u001b[39;22m: \u001b[34m57\u001b[39m installs, \u001b[34m0\u001b[39m updates, \u001b[34m0\u001b[39m removals\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!cd /content/CNN_CLASH/ && poetry install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DL5_RldPjML-",
        "outputId": "bace485c-53c5-4140-b154-ca792e7930a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wq1nwVVqjPiW"
      },
      "outputs": [],
      "source": [
        "!ln -s \"/content/drive/MyDrive/Candels/stamps/\" \"/content/CNN_CLASH/CANDELS/\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!python3 /content/CNN_CLASH/filter_data.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83515bYimtaX",
        "outputId": "8dfdb6c0-641f-438c-cd3e-1715ce561f0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3167, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGERwY15jRmu",
        "outputId": "398e60de-fd42-4fda-8168-99de026e316a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-12-23 03:19:16.550254: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "Epoch 1/150\n",
            "331/331 [==============================] - 148s 425ms/step - loss: 0.2406 - val_loss: 0.2375\n",
            "Epoch 2/150\n",
            "331/331 [==============================] - 137s 415ms/step - loss: 0.2336 - val_loss: 0.2289\n",
            "Epoch 3/150\n",
            "331/331 [==============================] - 137s 414ms/step - loss: 0.2303 - val_loss: 0.2285\n",
            "Epoch 4/150\n",
            "331/331 [==============================] - 135s 410ms/step - loss: 0.2258 - val_loss: 0.2311\n",
            "Epoch 5/150\n",
            "331/331 [==============================] - 136s 411ms/step - loss: 0.2201 - val_loss: 0.4225\n",
            "Epoch 6/150\n",
            "331/331 [==============================] - 135s 408ms/step - loss: 0.2116 - val_loss: 0.2317\n",
            "Epoch 7/150\n",
            "331/331 [==============================] - 172s 520ms/step - loss: 0.2108 - val_loss: 0.2528\n",
            "Epoch 8/150\n",
            "331/331 [==============================] - 134s 406ms/step - loss: 0.2077 - val_loss: 0.2545\n",
            "Epoch 9/150\n",
            "331/331 [==============================] - 135s 407ms/step - loss: 0.2071 - val_loss: 0.2470\n",
            "Epoch 10/150\n",
            "331/331 [==============================] - 135s 409ms/step - loss: 0.2059 - val_loss: 0.2445\n",
            "Epoch 11/150\n",
            "331/331 [==============================] - 181s 548ms/step - loss: 0.2031 - val_loss: 0.3021\n",
            "Epoch 12/150\n",
            "331/331 [==============================] - 135s 407ms/step - loss: 0.2003 - val_loss: 0.1994\n",
            "Epoch 13/150\n",
            "331/331 [==============================] - 134s 407ms/step - loss: 0.1973 - val_loss: 0.2867\n",
            "Epoch 14/150\n",
            "331/331 [==============================] - 134s 406ms/step - loss: 0.1999 - val_loss: 0.2877\n",
            "Epoch 15/150\n",
            "331/331 [==============================] - 134s 405ms/step - loss: 0.1977 - val_loss: 0.2679\n",
            "Epoch 16/150\n",
            "331/331 [==============================] - 134s 406ms/step - loss: 0.1981 - val_loss: 0.4156\n",
            "Epoch 17/150\n",
            "331/331 [==============================] - 133s 404ms/step - loss: 0.1973 - val_loss: 0.2532\n",
            "Epoch 18/150\n",
            "331/331 [==============================] - 134s 404ms/step - loss: 0.1936 - val_loss: 0.2647\n",
            "Epoch 19/150\n",
            "331/331 [==============================] - 134s 406ms/step - loss: 0.1975 - val_loss: 0.2570\n",
            "Epoch 20/150\n",
            "331/331 [==============================] - 133s 403ms/step - loss: 0.1956 - val_loss: 0.2331\n",
            "Epoch 21/150\n",
            "331/331 [==============================] - 134s 405ms/step - loss: 0.1948 - val_loss: 0.2592\n",
            "Epoch 22/150\n",
            "331/331 [==============================] - 134s 405ms/step - loss: 0.1956 - val_loss: 0.2626\n",
            "Epoch 23/150\n",
            "331/331 [==============================] - 134s 405ms/step - loss: 0.1949 - val_loss: 0.4935\n",
            "Epoch 24/150\n",
            "331/331 [==============================] - 133s 403ms/step - loss: 0.1999 - val_loss: 0.3081\n",
            "Epoch 25/150\n",
            "331/331 [==============================] - 133s 404ms/step - loss: 0.1937 - val_loss: 0.2480\n",
            "Epoch 26/150\n",
            "331/331 [==============================] - 133s 404ms/step - loss: 0.1977 - val_loss: 0.3236\n",
            "Epoch 27/150\n",
            "331/331 [==============================] - 133s 403ms/step - loss: 0.1955 - val_loss: 0.2578\n",
            "Epoch 28/150\n",
            "331/331 [==============================] - 133s 403ms/step - loss: 0.1946 - val_loss: 0.2586\n",
            "Epoch 29/150\n",
            "331/331 [==============================] - 133s 403ms/step - loss: 0.1936 - val_loss: 0.2580\n",
            "Epoch 30/150\n",
            "331/331 [==============================] - 134s 404ms/step - loss: 0.1940 - val_loss: 0.2812\n",
            "Epoch 31/150\n",
            "331/331 [==============================] - 133s 403ms/step - loss: 0.1926 - val_loss: 0.2615\n",
            "Epoch 32/150\n",
            "331/331 [==============================] - 133s 403ms/step - loss: 0.1918 - val_loss: 0.5081\n",
            "Epoch 33/150\n",
            "331/331 [==============================] - 133s 403ms/step - loss: 0.1939 - val_loss: 0.5118\n",
            "Epoch 34/150\n",
            "331/331 [==============================] - 132s 401ms/step - loss: 0.1897 - val_loss: 0.2532\n",
            "Epoch 35/150\n",
            "331/331 [==============================] - 133s 404ms/step - loss: 0.1917 - val_loss: 0.3671\n",
            "Epoch 36/150\n",
            "331/331 [==============================] - 133s 402ms/step - loss: 0.1919 - val_loss: 0.2670\n",
            "Epoch 37/150\n",
            "331/331 [==============================] - 133s 404ms/step - loss: 0.1891 - val_loss: 0.2659\n",
            "Epoch 38/150\n",
            "331/331 [==============================] - 133s 403ms/step - loss: 0.1899 - val_loss: 0.2811\n",
            "Epoch 39/150\n",
            "331/331 [==============================] - 133s 402ms/step - loss: 0.1878 - val_loss: 0.4711\n",
            "Epoch 40/150\n",
            "331/331 [==============================] - 133s 403ms/step - loss: 0.1869 - val_loss: 0.2584\n",
            "Epoch 41/150\n",
            "331/331 [==============================] - 133s 402ms/step - loss: 0.1873 - val_loss: 0.3126\n",
            "Epoch 42/150\n",
            "331/331 [==============================] - 133s 403ms/step - loss: 0.1904 - val_loss: 0.2666\n",
            "Epoch 43/150\n",
            "331/331 [==============================] - 133s 402ms/step - loss: 0.1851 - val_loss: 0.2897\n",
            "Epoch 44/150\n",
            "331/331 [==============================] - 133s 403ms/step - loss: 0.1852 - val_loss: 0.2926\n",
            "Epoch 45/150\n",
            "331/331 [==============================] - 133s 401ms/step - loss: 0.1882 - val_loss: 0.2578\n",
            "Epoch 46/150\n",
            "331/331 [==============================] - 134s 404ms/step - loss: 0.1866 - val_loss: 0.2502\n",
            "Epoch 47/150\n",
            "331/331 [==============================] - 133s 402ms/step - loss: 0.1844 - val_loss: 0.3375\n",
            "Epoch 48/150\n",
            "331/331 [==============================] - 133s 403ms/step - loss: 0.1847 - val_loss: 0.3578\n",
            "Epoch 49/150\n",
            "331/331 [==============================] - 133s 402ms/step - loss: 0.1943 - val_loss: 0.2974\n",
            "Epoch 50/150\n",
            "331/331 [==============================] - 133s 403ms/step - loss: 0.1878 - val_loss: 0.2524\n",
            "Epoch 51/150\n",
            "331/331 [==============================] - 134s 405ms/step - loss: 0.2156 - val_loss: 0.2188\n",
            "Epoch 52/150\n",
            "331/331 [==============================] - 133s 402ms/step - loss: 0.2260 - val_loss: 0.2337\n",
            "Epoch 53/150\n",
            "331/331 [==============================] - 133s 403ms/step - loss: 0.2193 - val_loss: 0.2918\n",
            "Epoch 54/150\n",
            "331/331 [==============================] - 132s 401ms/step - loss: 0.2066 - val_loss: 0.2717\n",
            "Epoch 55/150\n",
            "331/331 [==============================] - 181s 549ms/step - loss: 0.2116 - val_loss: 0.2355\n",
            "Epoch 56/150\n",
            "331/331 [==============================] - 133s 403ms/step - loss: 0.2247 - val_loss: 0.2399\n",
            "Epoch 57/150\n",
            "331/331 [==============================] - 133s 401ms/step - loss: 0.2052 - val_loss: 0.2555\n",
            "Epoch 58/150\n",
            "331/331 [==============================] - 134s 404ms/step - loss: 0.1953 - val_loss: 0.2250\n",
            "Epoch 59/150\n",
            "331/331 [==============================] - 133s 402ms/step - loss: 0.1922 - val_loss: 0.2507\n",
            "Epoch 60/150\n",
            "331/331 [==============================] - 133s 401ms/step - loss: 0.2028 - val_loss: 0.2582\n",
            "Epoch 61/150\n",
            "331/331 [==============================] - 133s 403ms/step - loss: 0.2216 - val_loss: 0.2775\n",
            "Epoch 62/150\n",
            "331/331 [==============================] - 133s 404ms/step - loss: 0.1962 - val_loss: 0.2534\n",
            "36/36 [==============================] - 1s 17ms/step - loss: 0.2502\n",
            "Score:  0.25019288063049316\n",
            "Metric:,  ['loss']\n"
          ]
        }
      ],
      "source": [
        "!cd /content/CNN_CLASH && python3 train.py CANDELS"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyNwltWL9szg5NiZglA416TV",
      "include_colab_link": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}